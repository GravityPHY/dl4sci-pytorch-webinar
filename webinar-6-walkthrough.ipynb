{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. A complete example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import colorama\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(precision=3)\n",
    "! pip3 -q install colorama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LeNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pytorch.org/tutorials/_images/mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture Details**\n",
    "\n",
    "+ Convolutional part:\n",
    "\n",
    "\n",
    "| Layer       | Name | Input channels | Output channels | Kernel | stride |\n",
    "| ----------- | :--: | :------------: | :-------------: | :----: | :----: |\n",
    "| Convolution |  C1  |       1        |        6        |  5x5   |   1    |\n",
    "| ReLU        |      |       6        |        6        |        |        |\n",
    "| MaxPooling  |  S2  |       6        |        6        |  2x2   |   2    |\n",
    "| Convolution |  C3  |       6        |       16        |  5x5   |   1    |\n",
    "| ReLU        |      |       16       |       16        |        |        |\n",
    "| MaxPooling  |  S4  |       16       |       16        |  2x2   |   2    |\n",
    "| Convolution |  C5  |       6        |       120       |  5x5   |   1    |\n",
    "| ReLU        |      |      120       |       120       |        |        |\n",
    "\n",
    "\n",
    "+ Fully Connected part:\n",
    "\n",
    "| Layer      | Name | Input size | Output size |\n",
    "| ---------- | :--: | :--------: | :---------: |\n",
    "| Linear     |  F5  |    120     |     84      |\n",
    "| ReLU       |      |            |             |\n",
    "| Linear     |  F6  |     84     |     10      |\n",
    "| LogSoftmax |      |            |             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            nn.Conv2d(6, 16, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 120, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        output = self.conv_net(imgs)\n",
    "        output = output.view(imgs.shape[0], -1)  # imgs.shape[0] is the batch_size\n",
    "        output = self.fully_connected(output)\n",
    "        return output        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print a network summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv_net): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (fully_connected): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
      "    (3): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv_net = LeNet5()\n",
    "print(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(params): 10\n",
      "\n",
      "conv_net.0.weight:\ttorch.Size([6, 1, 5, 5])\n",
      "conv_net.0.bias:\ttorch.Size([6])\n",
      "conv_net.3.weight:\ttorch.Size([16, 6, 5, 5])\n",
      "conv_net.3.bias:\ttorch.Size([16])\n",
      "conv_net.6.weight:\ttorch.Size([120, 16, 5, 5])\n",
      "conv_net.6.bias:\ttorch.Size([120])\n",
      "fully_connected.0.weight:\ttorch.Size([84, 120])\n",
      "fully_connected.0.bias:\ttorch.Size([84])\n",
      "fully_connected.2.weight:\ttorch.Size([10, 84])\n",
      "fully_connected.2.bias:\ttorch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "named_params = list(conv_net.named_parameters())\n",
    "print(\"len(params): %s\\n\" % len(named_params))\n",
    "for name, param in named_params:\n",
    "    print(\"%s:\\t%s\" % (name, param.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed network with a random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Probabilities: \n",
      "tensor([[-2.176, -2.340, -2.282, -2.345, -2.391, -2.319, -2.382, -2.251, -2.279,\n",
      "         -2.279]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "Probabilities: \n",
      "tensor([[0.114, 0.096, 0.102, 0.096, 0.092, 0.098, 0.092, 0.105, 0.102, 0.102]],\n",
      "       grad_fn=<ExpBackward>)\n",
      "\n",
      "out.shape: \n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)  # batch_size, num_channels, height, width\n",
    "out = conv_net(input)\n",
    "print(\"Log-Probabilities: \\n%s\\n\" % out)\n",
    "print(\"Probabilities: \\n%s\\n\" % torch.exp(out))\n",
    "print(\"out.shape: \\n%s\" % (out.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Loading the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('./data', \n",
    "                            train = True, \n",
    "                            download = True,\n",
    "                            transform = transformations)\n",
    "\n",
    "test_data = datasets.MNIST('./data', \n",
    "                            train = False, \n",
    "                            download = True,\n",
    "                            transform = transformations)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, device, num_epochs=3, lr=0.1):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"=\" * 20, \"Starting epoch %d\" % (epoch + 1), \"=\" * 20)\n",
    "        \n",
    "        model.train()  # Not necessary in our example, but still good practice.\n",
    "                       # Only models with nn.Dropout and nn.BatchNorm modules require it\n",
    "                \n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if batch_idx % 40 == 0:\n",
    "                print(\"Batch %d/%d, Loss=%.4f\" % (batch_idx, len(train_loader), loss.item()))\n",
    "        \n",
    "        train_acc = accuracy(model, train_loader, device)\n",
    "        test_acc = accuracy(model, test_loader, device)\n",
    "        \n",
    "        print(\"\\nAccuracy on training: %.2f%%\" % (100*train_acc))\n",
    "        print(\"Accuracy on test: %.2f%%\" % (100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, dataloader, device):\n",
    "    \"\"\" Computes the model's accuracy on the data provided by 'dataloader'\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    with torch.no_grad():  # deactivates autograd, reduces memory usage and speeds up computations\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            predictions = model(data).argmax(1)\n",
    "            num_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting epoch 1 ========================================\n",
      "Batch 0/235, Loss=0.0427\n",
      "Batch 40/235, Loss=0.0218\n",
      "Batch 80/235, Loss=0.0349\n",
      "Batch 120/235, Loss=0.0369\n",
      "Batch 160/235, Loss=0.0360\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8e60ca651113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconv_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-5b5414baed2f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, device, num_epochs, lr)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "conv_net = conv_net.to(device)\n",
    "\n",
    "train(conv_net, train_loader, test_loader, device, lr=2e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
