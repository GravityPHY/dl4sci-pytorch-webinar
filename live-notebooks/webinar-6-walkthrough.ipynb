{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. A complete example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import colorama\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LeNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pytorch.org/tutorials/_images/mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture Details**\n",
    "\n",
    "+ Convolutional part:\n",
    "\n",
    "\n",
    "| Layer       | Name | Input channels | Output channels | Kernel | stride |\n",
    "| ----------- | :--: | :------------: | :-------------: | :----: | :----: |\n",
    "| Convolution |  C1  |       1        |        6        |  5x5   |   1    |\n",
    "| ReLU        |      |       6        |        6        |        |        |\n",
    "| MaxPooling  |  S2  |       6        |        6        |  2x2   |   2    |\n",
    "| Convolution |  C3  |       6        |       16        |  5x5   |   1    |\n",
    "| ReLU        |      |       16       |       16        |        |        |\n",
    "| MaxPooling  |  S4  |       16       |       16        |  2x2   |   2    |\n",
    "| Convolution |  C5  |       6        |       120       |  5x5   |   1    |\n",
    "| ReLU        |      |      120       |       120       |        |        |\n",
    "\n",
    "\n",
    "+ Fully Connected part:\n",
    "\n",
    "| Layer      | Name | Input size | Output size |\n",
    "| ---------- | :--: | :--------: | :---------: |\n",
    "| Linear     |  F5  |    120     |     84      |\n",
    "| ReLU       |      |            |             |\n",
    "| Linear     |  F6  |     84     |     10      |\n",
    "| LogSoftmax |      |            |             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            nn.Conv2d(6, 16, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 120, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        output = self.conv_net(imgs)\n",
    "        output = output.view(imgs.shape[0], -1)  # imgs.shape[0] is the batch_size\n",
    "        output = self.fully_connected(output)\n",
    "        return output        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print a network summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv_net): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (fully_connected): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
      "    (3): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv_net = LeNet5()\n",
    "print(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(params): 10\n",
      "\n",
      "conv_net.0.weight:\ttorch.Size([6, 1, 5, 5])\n",
      "conv_net.0.bias:\ttorch.Size([6])\n",
      "conv_net.3.weight:\ttorch.Size([16, 6, 5, 5])\n",
      "conv_net.3.bias:\ttorch.Size([16])\n",
      "conv_net.6.weight:\ttorch.Size([120, 16, 5, 5])\n",
      "conv_net.6.bias:\ttorch.Size([120])\n",
      "fully_connected.0.weight:\ttorch.Size([84, 120])\n",
      "fully_connected.0.bias:\ttorch.Size([84])\n",
      "fully_connected.2.weight:\ttorch.Size([10, 84])\n",
      "fully_connected.2.bias:\ttorch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "named_params = list(conv_net.named_parameters())\n",
    "print(\"len(params): %s\\n\" % len(named_params))\n",
    "for name, param in named_params:\n",
    "    print(\"%s:\\t%s\" % (name, param.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed network with a random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Probabilities: \n",
      "tensor([[-2.249, -2.205, -2.397, -2.321, -2.260, -2.213, -2.420, -2.435, -2.282,\n",
      "         -2.276]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "Probabilities: \n",
      "tensor([[0.105, 0.110, 0.091, 0.098, 0.104, 0.109, 0.089, 0.088, 0.102, 0.103]],\n",
      "       grad_fn=<ExpBackward>)\n",
      "\n",
      "out.shape: \n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)  # batch_size, num_channels, height, width\n",
    "out = conv_net(input)\n",
    "print(\"Log-Probabilities: \\n%s\\n\" % out)\n",
    "print(\"Probabilities: \\n%s\\n\" % torch.exp(out))\n",
    "print(\"out.shape: \\n%s\" % (out.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Loading the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec5b0b930e3410a9651b711f88f47c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29169147072a4260a9a9ba4fd120bc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d10a05b6794de99c114ca575cc98b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2735dd0980fe449d9d71693e0e99d520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('../', \n",
    "                            train = True, \n",
    "                            download = True,\n",
    "                            transform = transformations)\n",
    "\n",
    "test_data = datasets.MNIST('../', \n",
    "                            train = False, \n",
    "                            download = True,\n",
    "                            transform = transformations)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, device, num_epochs=3, lr=0.1):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"=\" * 20, \"Starting epoch %d\" % (epoch + 1), \"=\" * 20)\n",
    "        \n",
    "        model.train()  # Not necessary in our example, but still good practice.\n",
    "                       # Only models with nn.Dropout and nn.BatchNorm modules require it\n",
    "                \n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if batch_idx % 40 == 0:\n",
    "                print(\"Batch %d/%d, Loss=%.4f\" % (batch_idx, len(train_loader), loss.item()))\n",
    "        \n",
    "        train_acc = accuracy(model, train_loader, device)\n",
    "        test_acc = accuracy(model, test_loader, device)\n",
    "        \n",
    "        print(\"\\nAccuracy on training: %.2f%%\" % (100*train_acc))\n",
    "        print(\"Accuracy on test: %.2f%%\" % (100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, dataloader, device):\n",
    "    \"\"\" Computes the model's accuracy on the data provided by 'dataloader'\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    with torch.no_grad():  # deactivates autograd, reduces memory usage and speeds up computations\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            predictions = model(data).argmax(1)\n",
    "            num_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting epoch 1 ====================\n",
      "Batch 0/235, Loss=2.3070\n",
      "Batch 40/235, Loss=0.6044\n",
      "Batch 80/235, Loss=0.3776\n",
      "Batch 120/235, Loss=0.2005\n",
      "Batch 160/235, Loss=0.1719\n",
      "Batch 200/235, Loss=0.2329\n",
      "\n",
      "Accuracy on training: 96.26%\n",
      "Accuracy on test: 96.58%\n",
      "==================== Starting epoch 2 ====================\n",
      "Batch 0/235, Loss=0.1199\n",
      "Batch 40/235, Loss=0.1055\n",
      "Batch 80/235, Loss=0.0533\n",
      "Batch 120/235, Loss=0.1053\n",
      "Batch 160/235, Loss=0.1063\n",
      "Batch 200/235, Loss=0.1745\n",
      "\n",
      "Accuracy on training: 97.95%\n",
      "Accuracy on test: 98.17%\n",
      "==================== Starting epoch 3 ====================\n",
      "Batch 0/235, Loss=0.0442\n",
      "Batch 40/235, Loss=0.0639\n",
      "Batch 80/235, Loss=0.0442\n",
      "Batch 120/235, Loss=0.0517\n",
      "Batch 160/235, Loss=0.0331\n",
      "Batch 200/235, Loss=0.0443\n",
      "\n",
      "Accuracy on training: 98.41%\n",
      "Accuracy on test: 98.58%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "conv_net = conv_net.to(device)\n",
    "\n",
    "train(conv_net, train_loader, test_loader, device, lr=2e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
